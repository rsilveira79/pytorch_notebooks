{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In addition to linear function, on FF NN we add a non-linear function (activation function)\n",
    "## Ex.: ReLU, sigmoid, Tanh, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Steps \n",
    "# Step 1 - Load the dataset\n",
    "# Step 2 - Making the dataset iterable\n",
    "# Step 3 - Create model class\n",
    "# Step 4 - Instantiate model class\n",
    "# Step 5 - Instantiate loss class\n",
    "# Step 6 - Instantiate optimizer class\n",
    "# Step 7 - Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dataset\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "## Step 1 - loading the dataset\n",
    "train_dataset = dataset.MNIST(root = './data/',\n",
    "                             train = True,\n",
    "                             transform = transforms.ToTensor(),\n",
    "                             download = True)\n",
    "test_dataset = dataset.MNIST(root = './data/',\n",
    "                             train = False,\n",
    "                             transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 2 - Making the dataset iterable\n",
    "batch_size = 100\n",
    "n_iters = 5000\n",
    "num_epochs = n_iters/(len(train_dataset)/batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x10a0d6668>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3 - Create model class\n",
    "class FFNeuralNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FFNeuralNet, self).__init__()\n",
    "        ## Linear function\n",
    "        self.fcl = nn.Linear(input_dim, hidden_dim)\n",
    "        ## Non-linearity\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        ## Linear function (readout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## Linear function\n",
    "        out = self.fcl(x)\n",
    "        ## Non-linearity\n",
    "        out = self.sigmoid(out)\n",
    "        ## Linear function (readout)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 4 - Instantiate model class\n",
    "input_dim = 28 * 28\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFNeuralNet (\n",
       "  (fcl): Linear (784 -> 100)\n",
       "  (sigmoid): Sigmoid ()\n",
       "  (fc2): Linear (100 -> 10)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_dim =100\n",
    "output_dim = 10\n",
    "model = FFNeuralNet(input_dim, hidden_dim, output_dim)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 5 - Instantiate the loss class\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 6 - Instantiate the optimizer class\n",
    "learning_rate = 0.01\n",
    "optim = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x10a763b48>\n",
      "4\n",
      "torch.Size([100, 784])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())\n",
    "print(len(list(model.parameters())))\n",
    "## Hidden layer\n",
    "print(list(model.parameters())[0].size())\n",
    "## FC1 Bias\n",
    "print(list(model.parameters())[1].size())\n",
    "## FC2 parameters\n",
    "print(list(model.parameters())[2].size())\n",
    "## FC2 bias parameters\n",
    "print(list(model.parameters())[3].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       " 1.2122e-02 -1.7747e-02 -6.8608e-03  ...  -1.4843e-02 -2.7559e-02 -9.5374e-03\n",
       " 5.8333e-03  7.9092e-03  4.4225e-03  ...   3.0566e-02  3.3487e-02  2.4239e-02\n",
       "-2.8226e-02 -2.2675e-02 -2.7151e-03  ...  -1.3625e-02 -1.8539e-02  2.5054e-02\n",
       "                ...                   ⋱                   ...                \n",
       " 1.9190e-02 -2.5270e-02 -1.1787e-02  ...   8.9276e-03 -1.9335e-04 -1.9708e-02\n",
       " 3.2956e-02  3.0581e-02 -1.2646e-03  ...   1.8732e-02 -3.0821e-02  3.2544e-02\n",
       "-2.4731e-02  2.0252e-03 -2.7786e-02  ...   3.1968e-02 -2.2849e-02 -2.7611e-02\n",
       "[torch.FloatTensor of size 100x784]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500, Loss 0.8536343574523926, Accuracy 83.19\n",
      "Iteration 1000, Loss 0.7695441246032715, Accuracy 84.26\n",
      "Iteration 1500, Loss 0.7384187579154968, Accuracy 85.44\n",
      "Iteration 2000, Loss 0.746574342250824, Accuracy 86.21\n",
      "Iteration 2500, Loss 0.5106121897697449, Accuracy 86.8\n",
      "Iteration 3000, Loss 0.43554842472076416, Accuracy 87.32\n",
      "Iteration 3500, Loss 0.608245849609375, Accuracy 87.76\n",
      "Iteration 4000, Loss 0.4576670527458191, Accuracy 88.13\n",
      "Iteration 4500, Loss 0.4395284950733185, Accuracy 88.37\n"
     ]
    }
   ],
   "source": [
    "## Step 7 - Train the model\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        ## Load images as variables\n",
    "        images = Variable(images.view(-1,28*28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        ## Clear gradients\n",
    "        optim.zero_grad()\n",
    "\n",
    "        ## Forward pass to get output\n",
    "        outputs = model.forward(images)\n",
    "\n",
    "        ## Calculate loss function\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        ## Backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        ## Update parameters\n",
    "        optim.step()\n",
    "\n",
    "        iter +=1\n",
    "\n",
    "        if iter %500 ==0:\n",
    "            ## Calculate accuracy\n",
    "            correct = 0\n",
    "            total =0\n",
    "\n",
    "            ## Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                ## Variablea\n",
    "                images = Variable(images.view(-1,28*28))\n",
    "                ## Forward\n",
    "                output = model.forward(images)\n",
    "                ## Get predictions\n",
    "                _, predicted = torch.max(output.data,1)\n",
    "                ## Total number of labels\n",
    "                total += labels.size(0)\n",
    "                ## Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            accuracy = 100*correct/total\n",
    "            ## Print loss\n",
    "            print('Iteration {}, Loss {}, Accuracy {}'.format(iter,loss.data[0],accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.2122e-02 -1.7747e-02 -6.8608e-03  ...  -1.4843e-02 -2.7559e-02 -9.5374e-03\n",
       " 5.8333e-03  7.9092e-03  4.4225e-03  ...   3.0566e-02  3.3487e-02  2.4239e-02\n",
       "-2.8226e-02 -2.2675e-02 -2.7151e-03  ...  -1.3625e-02 -1.8539e-02  2.5054e-02\n",
       "                ...                   ⋱                   ...                \n",
       "-1.1572e-02 -1.1441e-02  2.2753e-02  ...  -3.1234e-02 -1.4218e-02 -2.9890e-02\n",
       " 1.9190e-02 -2.5270e-02 -1.1787e-02  ...   8.9276e-03 -1.9335e-04 -1.9708e-02\n",
       " 3.2956e-02  3.0581e-02 -1.2646e-03  ...   1.8732e-02 -3.0821e-02  3.2544e-02\n",
       "[torch.FloatTensor of size 99x784]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[0][0:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model B - with Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNeuralNet_tanh(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FFNeuralNet_tanh, self).__init__()\n",
    "        ## Linear function\n",
    "        self.fcl = nn.Linear(input_dim, hidden_dim)\n",
    "        ## Non-linearity\n",
    "        self.tanh = nn.Tanh()\n",
    "        ## Linear function (readout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## Linear function\n",
    "        out = self.fcl(x)\n",
    "        ## Non-linearity\n",
    "        out = self.tanh(out)\n",
    "        ## Linear function (readout)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tanh = FFNeuralNet_tanh(input_dim, hidden_dim, output_dim)\n",
    "learning_rate = 0.01\n",
    "optim = torch.optim.SGD(model_tanh.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500, Loss 0.9005258083343506, Accuracy 82.19\n",
      "Iteration 1000, Loss 0.5544187426567078, Accuracy 86.61\n",
      "Iteration 1500, Loss 0.4598257541656494, Accuracy 88.45\n",
      "Iteration 2000, Loss 0.39953848719596863, Accuracy 89.17\n",
      "Iteration 2500, Loss 0.47001609206199646, Accuracy 89.73\n",
      "Iteration 3000, Loss 0.28009968996047974, Accuracy 90.13\n",
      "Iteration 3500, Loss 0.448478102684021, Accuracy 90.37\n",
      "Iteration 4000, Loss 0.2781924307346344, Accuracy 90.95\n",
      "Iteration 4500, Loss 0.49368488788604736, Accuracy 91.23\n"
     ]
    }
   ],
   "source": [
    "## Step 7 - Train the model\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        ## Load images as variables\n",
    "        images = Variable(images.view(-1,28*28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        ## Clear gradients\n",
    "        optim.zero_grad()\n",
    "\n",
    "        ## Forward pass to get output\n",
    "        outputs = model_tanh.forward(images)\n",
    "\n",
    "        ## Calculate loss function\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        ## Backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        ## Update parameters\n",
    "        optim.step()\n",
    "\n",
    "        iter +=1\n",
    "\n",
    "        if iter %500 ==0:\n",
    "            ## Calculate accuracy\n",
    "            correct = 0\n",
    "            total =0\n",
    "\n",
    "            ## Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                ## Variablea\n",
    "                images = Variable(images.view(-1,28*28))\n",
    "                ## Forward\n",
    "                output = model_tanh.forward(images)\n",
    "                ## Get predictions\n",
    "                _, predicted = torch.max(output.data,1)\n",
    "                ## Total number of labels\n",
    "                total += labels.size(0)\n",
    "                ## Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            accuracy = 100*correct/total\n",
    "            ## Print loss\n",
    "            print('Iteration {}, Loss {}, Accuracy {}'.format(iter,loss.data[0],accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model C - with ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNeuralNet_relu(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FFNeuralNet_relu, self).__init__()\n",
    "        ## Linear function\n",
    "        self.fcl = nn.Linear(input_dim, hidden_dim)\n",
    "        ## Non-linearity\n",
    "        self.relu = nn.ReLU()\n",
    "        ## Linear function (readout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## Linear function\n",
    "        out = self.fcl(x)\n",
    "        ## Non-linearity\n",
    "        out = self.relu(out)\n",
    "        ## Linear function (readout)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relu = FFNeuralNet_relu(input_dim, hidden_dim, output_dim)\n",
    "learning_rate = 0.01\n",
    "optim = torch.optim.SGD(model_relu.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500, Loss 1.0430890321731567, Accuracy 81.68\n",
      "Iteration 1000, Loss 0.5451216697692871, Accuracy 86.72\n",
      "Iteration 1500, Loss 0.4751785397529602, Accuracy 88.75\n",
      "Iteration 2000, Loss 0.5545175671577454, Accuracy 89.44\n",
      "Iteration 2500, Loss 0.5666353702545166, Accuracy 90.1\n",
      "Iteration 3000, Loss 0.42353352904319763, Accuracy 90.42\n",
      "Iteration 3500, Loss 0.38164427876472473, Accuracy 90.79\n",
      "Iteration 4000, Loss 0.2604667544364929, Accuracy 91.01\n",
      "Iteration 4500, Loss 0.5295299291610718, Accuracy 91.4\n"
     ]
    }
   ],
   "source": [
    "## Step 7 - Train the model\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        ## Load images as variables\n",
    "        images = Variable(images.view(-1,28*28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        ## Clear gradients\n",
    "        optim.zero_grad()\n",
    "\n",
    "        ## Forward pass to get output\n",
    "        outputs = model_relu.forward(images)\n",
    "\n",
    "        ## Calculate loss function\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        ## Backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        ## Update parameters\n",
    "        optim.step()\n",
    "\n",
    "        iter +=1\n",
    "\n",
    "        if iter %500 ==0:\n",
    "            ## Calculate accuracy\n",
    "            correct = 0\n",
    "            total =0\n",
    "\n",
    "            ## Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                ## Variablea\n",
    "                images = Variable(images.view(-1,28*28))\n",
    "                ## Forward\n",
    "                output = model_relu.forward(images)\n",
    "                ## Get predictions\n",
    "                _, predicted = torch.max(output.data,1)\n",
    "                ## Total number of labels\n",
    "                total += labels.size(0)\n",
    "                ## Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            accuracy = 100*correct/total\n",
    "            ## Print loss\n",
    "            print('Iteration {}, Loss {}, Accuracy {}'.format(iter,loss.data[0],accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model D - 2 hiddel with ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNeuralNet_relu2(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FFNeuralNet_relu2, self).__init__()\n",
    "        ## Linear function\n",
    "        self.fcl = nn.Linear(input_dim, hidden_dim)\n",
    "        ## Non-linearity\n",
    "        self.relu1 = nn.ReLU()\n",
    "        ## Linear function \n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        ## Non-linearity\n",
    "        self.relu2 = nn.ReLU()\n",
    "        ## Linear function (readout)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## Linear function\n",
    "        out = self.fcl(x)\n",
    "        ## Non-linearity\n",
    "        out = self.relu1(out)\n",
    "        ## Linear function \n",
    "        out = self.fc2(out)\n",
    "        ## Non-linear 2\n",
    "        out = self.relu2(out)\n",
    "        ## Linear (readout)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relu2 = FFNeuralNet_relu2(input_dim, hidden_dim, output_dim)\n",
    "learning_rate = 0.01\n",
    "hidden_dim = 200\n",
    "optim = torch.optim.SGD(model_relu2.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500, Loss 1.6175955533981323, Accuracy 71.9\n",
      "Iteration 1000, Loss 0.6780022382736206, Accuracy 81.95\n",
      "Iteration 1500, Loss 0.4977650046348572, Accuracy 86.57\n",
      "Iteration 2000, Loss 0.500176727771759, Accuracy 88.56\n",
      "Iteration 2500, Loss 0.38205471634864807, Accuracy 89.61\n",
      "Iteration 3000, Loss 0.3401462137699127, Accuracy 90.3\n",
      "Iteration 3500, Loss 0.3249531686306, Accuracy 90.68\n",
      "Iteration 4000, Loss 0.3053443431854248, Accuracy 91.25\n",
      "Iteration 4500, Loss 0.36587414145469666, Accuracy 91.7\n"
     ]
    }
   ],
   "source": [
    "## Step 7 - Train the model\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        ## Load images as variables\n",
    "        images = Variable(images.view(-1,28*28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        ## Clear gradients\n",
    "        optim.zero_grad()\n",
    "\n",
    "        ## Forward pass to get output\n",
    "        outputs = model_relu2.forward(images)\n",
    "\n",
    "        ## Calculate loss function\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        ## Backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        ## Update parameters\n",
    "        optim.step()\n",
    "\n",
    "        iter +=1\n",
    "\n",
    "        if iter %500 ==0:\n",
    "            ## Calculate accuracy\n",
    "            correct = 0\n",
    "            total =0\n",
    "\n",
    "            ## Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                ## Variablea\n",
    "                images = Variable(images.view(-1,28*28))\n",
    "                ## Forward\n",
    "                output = model_relu2.forward(images)\n",
    "                ## Get predictions\n",
    "                _, predicted = torch.max(output.data,1)\n",
    "                ## Total number of labels\n",
    "                total += labels.size(0)\n",
    "                ## Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            accuracy = 100*correct/total\n",
    "            ## Print loss\n",
    "            print('Iteration {}, Loss {}, Accuracy {}'.format(iter,loss.data[0],accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From CPU to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('GPU available')\n",
    "    model_relu2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500, Loss 0.07540509104728699, Accuracy 96.71\n",
      "Iteration 1000, Loss 0.16496196389198303, Accuracy 96.81\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-e78be99c721c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m## Backpropagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m## Update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/nlp/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/nlp/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Step 7 - Train the model\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        ## Load images as variables\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.view(-1,28*28).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1,28*28))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "        ## Clear gradients\n",
    "        optim.zero_grad()\n",
    "\n",
    "        ## Forward pass to get output\n",
    "        outputs = model_relu2.forward(images)\n",
    "\n",
    "        ## Calculate loss function\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        ## Backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        ## Update parameters\n",
    "        optim.step()\n",
    "\n",
    "        iter +=1\n",
    "\n",
    "        if iter %500 ==0:\n",
    "            ## Calculate accuracy\n",
    "            correct = 0\n",
    "            total =0\n",
    "\n",
    "            ## Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                ## Variablea\n",
    "                if torch.cuda.is_available():\n",
    "                    images = Variable(images.view(-1,28*28).cuda())\n",
    "                else:\n",
    "                    images = Variable(images.view(-1,28*28))\n",
    "                ## Forward\n",
    "                output = model_relu2.forward(images)\n",
    "                ## Get predictions\n",
    "                _, predicted = torch.max(output.data,1)\n",
    "                ## Total number of labels\n",
    "                total += labels.size(0)\n",
    "                ## Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            accuracy = 100*correct/total\n",
    "            ## Print loss\n",
    "            print('Iteration {}, Loss {}, Accuracy {}'.format(iter,loss.data[0],accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
